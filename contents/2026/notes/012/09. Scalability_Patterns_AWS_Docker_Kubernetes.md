# Scalability Patterns: AWS, Docker, and Kubernetes

## In-Depth Guide to Building Scalable Systems

---

## Table of Contents

1. [Scalability Fundamentals](#1-scalability-fundamentals)
2. [Horizontal Scaling Patterns](#2-horizontal-scaling-patterns)
3. [Vertical Scaling Patterns](#3-vertical-scaling-patterns)
4. [Auto-Scaling Strategies](#4-auto-scaling-strategies)
5. [Load Balancing Patterns](#5-load-balancing-patterns)
6. [Caching Patterns](#6-caching-patterns)
7. [Database Scaling Patterns](#7-database-scaling-patterns)
8. [Container Orchestration Scaling](#8-container-orchestration-scaling)
9. [Real-World Implementation](#9-real-world-implementation)
10. [Best Practices and Patterns](#10-best-practices-and-patterns)

---

## 1. Scalability Fundamentals

### 1.1 Types of Scalability

**Horizontal Scaling (Scale Out)**:
- Add more instances/nodes
- Distribute load across multiple servers
- Better for cloud environments
- Example: 1 server → 10 servers

**Vertical Scaling (Scale Up)**:
- Increase resources of existing instance
- More CPU, memory, storage
- Limited by hardware
- Example: 2 vCPU, 4GB → 8 vCPU, 32GB

**Diagonal Scaling**:
- Combination of horizontal and vertical
- Add instances AND increase resources
- Most flexible approach

### 1.2 Scalability Dimensions

```
Scalability Dimensions:
├── Compute Scaling
│   ├── Application servers
│   ├── Processing power
│   └── Concurrent requests
├── Storage Scaling
│   ├── Database capacity
│   ├── File storage
│   └── Cache capacity
├── Network Scaling
│   ├── Bandwidth
│   ├── Connection limits
│   └── CDN distribution
└── Data Scaling
    ├── Read replicas
    ├── Sharding
    └── Partitioning
```

### 1.3 Scalability Metrics

**Key Metrics**:
- **Throughput**: Requests per second (RPS)
- **Latency**: Response time (p50, p95, p99)
- **Concurrent Users**: Simultaneous users
- **Resource Utilization**: CPU, memory, I/O
- **Cost per Request**: Efficiency metric

---

## 2. Horizontal Scaling Patterns

### 2.1 Stateless Application Pattern

**Principle**: Applications should be stateless to enable horizontal scaling.

**Docker Implementation**:
```dockerfile
# Dockerfile - Stateless Spring Boot Application
FROM openjdk:17-jre-slim

WORKDIR /app

# Copy JAR (no state stored in container)
COPY target/myapp.jar app.jar

# Expose port
EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s \
  CMD curl -f http://localhost:8080/actuator/health || exit 1

# Run application
ENTRYPOINT ["java", "-jar", "app.jar"]
```

**Java Application: Stateless Design**:
```java
@RestController
@RequestMapping("/api/orders")
public class OrderController {
    
    // ❌ BAD: Stateful (session storage in memory)
    // private Map<String, Order> sessionOrders = new HashMap<>();
    
    // ✅ GOOD: Stateless (external storage)
    private final OrderRepository orderRepository;
    private final RedisTemplate<String, Object> redisTemplate;
    
    @PostMapping
    public ResponseEntity<Order> createOrder(@RequestBody OrderRequest request) {
        // Store in database (shared state)
        Order order = orderService.createOrder(request);
        
        // Store session in Redis (shared state)
        redisTemplate.opsForValue().set(
            "session:" + request.getSessionId(),
            order,
            Duration.ofMinutes(30)
        );
        
        return ResponseEntity.ok(order);
    }
}
```

**Kubernetes Deployment (Stateless)**:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3  # Horizontal scaling: 3 instances
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myapp:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: host
        # No volumes (stateless)
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
```

**AWS ECS Task Definition (Stateless)**:
```json
{
  "family": "myapp-task",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "containerDefinitions": [
    {
      "name": "myapp",
      "image": "123456789.dkr.ecr.us-east-1.amazonaws.com/myapp:latest",
      "essential": true,
      "portMappings": [
        {
          "containerPort": 8080,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "SPRING_PROFILES_ACTIVE",
          "value": "production"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/myapp",
          "awslogs-region": "us-east-1"
        }
      }
    }
  ]
}
```

### 2.2 Microservices Scaling Pattern

**Principle**: Scale services independently based on their load.

**Architecture**:
```
┌─────────────────────────────────────────────────────────┐
│                    Load Balancer                         │
└──────────────┬──────────────────────────────────────────┘
               │
    ┌──────────┼──────────┐
    ▼         ▼          ▼
┌────────┐ ┌────────┐ ┌────────┐
│ User   │ │ Order  │ │Product │
│Service │ │Service │ │Service │
│(3 pods)│ │(5 pods)│ │(2 pods)│
└────────┘ └────────┘ └────────┘
```

**Kubernetes: Independent Service Scaling**:
```yaml
# User Service - Lower load, fewer replicas
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
spec:
  replicas: 3
  # ... configuration

---
# Order Service - Higher load, more replicas
apiVersion: apps/v1
kind: Deployment
metadata:
  name: order-service
spec:
  replicas: 10
  # ... configuration

---
# Product Service - Medium load
apiVersion: apps/v1
kind: Deployment
metadata:
  name: product-service
spec:
  replicas: 5
  # ... configuration
```

**AWS ECS: Service-Level Scaling**:
```yaml
# User Service
Service:
  Name: user-service
  DesiredCount: 3
  AutoScaling:
    MinCapacity: 2
    MaxCapacity: 5

# Order Service
Service:
  Name: order-service
  DesiredCount: 10
  AutoScaling:
    MinCapacity: 5
    MaxCapacity: 20
```

### 2.3 Container Scaling with Docker Swarm

**Docker Swarm Scaling**:
```bash
# Initialize swarm
docker swarm init

# Create service with replicas
docker service create \
  --name myapp \
  --replicas 3 \
  --publish 8080:8080 \
  myapp:latest

# Scale service
docker service scale myapp=10

# Update service
docker service update --replicas 15 myapp
```

**Docker Compose with Scaling**:
```yaml
version: '3.8'
services:
  app:
    image: myapp:latest
    deploy:
      replicas: 5
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
    ports:
      - "8080:8080"
```

---

## 3. Vertical Scaling Patterns

### 3.1 Resource Scaling

**Kubernetes: Vertical Pod Autoscaler (VPA)**:
```yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: myapp-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: myapp
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 4
        memory: 8Gi
      controlledResources: ["cpu", "memory"]
```

**AWS ECS: Task Resource Scaling**:
```json
{
  "containerDefinitions": [
    {
      "name": "myapp",
      "cpu": 1024,  // 1 vCPU
      "memory": 2048,  // 2GB
      // Scale up: increase cpu and memory
      // cpu: 2048 (2 vCPU)
      // memory: 4096 (4GB)
    }
  ]
}
```

**Java Application: Resource-Aware Scaling**:
```java
@Component
public class ResourceMonitor {
    
    private final MeterRegistry meterRegistry;
    
    @Scheduled(fixedRate = 60000) // Every minute
    public void monitorResources() {
        MemoryMXBean memoryBean = ManagementFactory.getMemoryMXBean();
        MemoryUsage heapUsage = memoryBean.getHeapMemoryUsage();
        
        long usedMemory = heapUsage.getUsed();
        long maxMemory = heapUsage.getMax();
        double memoryUsagePercent = (usedMemory * 100.0) / maxMemory;
        
        // Record metric
        Gauge.builder("jvm.memory.usage.percent", () -> memoryUsagePercent)
            .register(meterRegistry);
        
        // Alert if memory usage > 80%
        if (memoryUsagePercent > 80) {
            log.warn("High memory usage: {}%", memoryUsagePercent);
        }
    }
}
```

### 3.2 Database Vertical Scaling

**AWS RDS: Instance Scaling**:
```yaml
# Small instance
DBInstanceClass: db.t3.micro
  - 2 vCPU, 1GB RAM
  - Cost: ~$15/month

# Medium instance
DBInstanceClass: db.t3.medium
  - 2 vCPU, 4GB RAM
  - Cost: ~$60/month

# Large instance
DBInstanceClass: db.m5.large
  - 2 vCPU, 8GB RAM
  - Cost: ~$150/month

# XLarge instance
DBInstanceClass: db.m5.xlarge
  - 4 vCPU, 16GB RAM
  - Cost: ~$300/month
```

**Scaling Strategy**:
```bash
# Modify RDS instance (zero downtime)
aws rds modify-db-instance \
  --db-instance-identifier myapp-db \
  --db-instance-class db.m5.xlarge \
  --apply-immediately
```

---

## 4. Auto-Scaling Strategies

### 4.1 Kubernetes Horizontal Pod Autoscaler (HPA)

**HPA Configuration**:
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max
```

**Custom Metrics HPA**:
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa-custom
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 3
  maxReplicas: 50
  metrics:
  - type: Pods
    pods:
      metric:
        name: requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
```

**Java Application: Custom Metrics**:
```java
@Service
public class OrderService {
    
    private final MeterRegistry meterRegistry;
    private final Counter requestCounter;
    
    public OrderService(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.requestCounter = Counter.builder("orders.requests")
            .description("Number of order requests")
            .register(meterRegistry);
    }
    
    public Order createOrder(OrderRequest request) {
        requestCounter.increment();
        // Process order
        return processOrder(request);
    }
}
```

**Prometheus Adapter for Custom Metrics**:
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: adapter-config
data:
  config.yaml: |
    rules:
    - seriesQuery: 'orders_requests_total'
      resources:
        overrides:
          namespace: {resource: "namespace"}
          pod: {resource: "pod"}
      name:
        matches: "^(.*)_total"
        as: "${1}_per_second"
      metricsQuery: 'rate(<<.Series>>{<<.LabelMatchers>>}[2m])'
```

### 4.2 AWS ECS Auto-Scaling

**ECS Service Auto-Scaling**:
```json
{
  "ServiceName": "myapp-service",
  "ClusterName": "myapp-cluster",
  "DesiredCount": 3,
  "AutoScalingConfiguration": {
    "MinCapacity": 3,
    "MaxCapacity": 20,
    "TargetTrackingScalingPolicies": [
      {
        "PolicyName": "cpu-scaling",
        "TargetValue": 70.0,
        "PredefinedMetricSpecification": {
          "PredefinedMetricType": "ECSServiceAverageCPUUtilization"
        },
        "ScaleInCooldown": 60,
        "ScaleOutCooldown": 60
      },
      {
        "PolicyName": "memory-scaling",
        "TargetValue": 80.0,
        "PredefinedMetricSpecification": {
          "PredefinedMetricType": "ECSServiceAverageMemoryUtilization"
        },
        "ScaleInCooldown": 60,
        "ScaleOutCooldown": 60
      }
    ]
  }
}
```

**CloudFormation: ECS Auto-Scaling**:
```yaml
Resources:
  ECSServiceAutoScaling:
    Type: AWS::ApplicationAutoScaling::ScalableTarget
    Properties:
      MaxCapacity: 20
      MinCapacity: 3
      ResourceId: !Sub 'service/${ECSCluster}/${ECSService}'
      RoleARN: !GetAtt AutoScalingRole.Arn
      ScalableDimension: ecs:service:DesiredCount
      ServiceNamespace: ecs
  
  ECSServiceScalingPolicy:
    Type: AWS::ApplicationAutoScaling::ScalingPolicy
    Properties:
      PolicyName: cpu-scaling-policy
      PolicyType: TargetTrackingScaling
      ScalingTargetId: !Ref ECSServiceAutoScaling
      TargetTrackingScalingPolicyConfiguration:
        TargetValue: 70.0
        PredefinedMetricSpecification:
          PredefinedMetricType: ECSServiceAverageCPUUtilization
        ScaleInCooldown: 300
        ScaleOutCooldown: 60
```

### 4.3 AWS EC2 Auto Scaling Groups

**Auto Scaling Group Configuration**:
```yaml
Resources:
  AutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      MinSize: 2
      MaxSize: 10
      DesiredCapacity: 3
      VPCZoneIdentifier:
        - subnet-123
        - subnet-456
      LaunchTemplate:
        LaunchTemplateId: !Ref LaunchTemplate
        Version: !GetAtt LaunchTemplate.LatestVersionNumber
      HealthCheckType: ELB
      HealthCheckGracePeriod: 300
      TargetGroupARNs:
        - !Ref TargetGroup
  
  ScalingPolicy:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      AutoScalingGroupName: !Ref AutoScalingGroup
      PolicyType: TargetTrackingScaling
      TargetTrackingConfiguration:
        PredefinedMetricSpecification:
          PredefinedMetricType: ASGAverageCPUUtilization
        TargetValue: 70.0
```

---

## 5. Load Balancing Patterns

### 5.1 Application Load Balancer (ALB)

**AWS ALB Configuration**:
```yaml
Resources:
  ApplicationLoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: myapp-alb
      Type: application
      Scheme: internet-facing
      Subnets:
        - subnet-public-1
        - subnet-public-2
      SecurityGroups:
        - !Ref ALBSecurityGroup
      Listeners:
        - Protocol: HTTP
          Port: 80
          DefaultActions:
            - Type: redirect
              RedirectConfig:
                Protocol: HTTPS
                Port: 443
                StatusCode: HTTP_301
        - Protocol: HTTPS
          Port: 443
          Certificates:
            - CertificateArn: !Ref SSLCertificate
          DefaultActions:
            - Type: forward
              TargetGroupArn: !Ref TargetGroup
  
  TargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: myapp-tg
      Port: 8080
      Protocol: HTTP
      VpcId: !Ref VPC
      TargetType: ip
      HealthCheckPath: /actuator/health
      HealthCheckIntervalSeconds: 30
      HealthCheckTimeoutSeconds: 5
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 3
      Matcher:
        HttpCode: 200
```

**Kubernetes: Service and Ingress**:
```yaml
# Service (ClusterIP)
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  type: ClusterIP
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 8080
---
# Ingress (ALB)
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  annotations:
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/healthcheck-path: /actuator/health
    alb.ingress.kubernetes.io/load-balancer-type: application
spec:
  ingressClassName: alb
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80
```

### 5.2 Load Balancing Algorithms

**ALB Algorithms**:
```yaml
Load Balancing Algorithms:
  Round Robin:
    - Distribute requests evenly
    - Default for ALB
  
  Least Connections:
    - Route to server with fewest connections
    - Better for long-lived connections
  
  IP Hash:
    - Route based on client IP
    - Ensures same client → same server
    - Good for session affinity
```

**Kubernetes: Service Load Balancing**:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-algorithm: "least_connections"
spec:
  type: LoadBalancer
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 10800
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 8080
```

### 5.3 Sticky Sessions (Session Affinity)

**Java Application: Session Management**:
```java
@Configuration
public class SessionConfiguration {
    
    @Bean
    public RedisSessionRepository sessionRepository(RedisConnectionFactory connectionFactory) {
        RedisSessionRepository repository = new RedisSessionRepository(connectionFactory);
        repository.setDefaultMaxInactiveInterval(1800); // 30 minutes
        return repository;
    }
    
    @Bean
    public HttpSessionIdResolver httpSessionIdResolver() {
        // Use cookie-based session (works with load balancer)
        return CookieHttpSessionIdResolver();
    }
}
```

**ALB: Sticky Sessions**:
```yaml
TargetGroupAttributes:
  - Key: stickiness.enabled
    Value: true
  - Key: stickiness.type
    Value: lb_cookie
  - Key: stickiness.lb_cookie.duration_seconds
    Value: 3600
```

---

## 6. Caching Patterns

### 6.1 Multi-Layer Caching

**Architecture**:
```
Request
  │
  ▼
┌─────────────────┐
│  CDN (CloudFront)│  ← L1: Static assets, 24h TTL
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│ Application     │
│  Memory Cache   │  ← L2: Hot data, 5min TTL
│  (Caffeine)     │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  Redis Cache    │  ← L3: Frequently accessed, 1h TTL
│  (ElastiCache)  │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│   Database      │  ← L4: Source of truth
│     (RDS)       │
└─────────────────┘
```

**Java Implementation**:
```java
@Configuration
@EnableCaching
public class CacheConfiguration {
    
    // L2: Application Memory Cache
    @Bean
    public CacheManager caffeineCacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager();
        cacheManager.setCaffeine(Caffeine.newBuilder()
            .maximumSize(1000)
            .expireAfterWrite(5, TimeUnit.MINUTES)
            .recordStats());
        return cacheManager;
    }
    
    // L3: Redis Cache
    @Bean
    public CacheManager redisCacheManager(RedisConnectionFactory connectionFactory) {
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofHours(1))
            .serializeKeysWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new GenericJackson2JsonRedisSerializer()));
        
        return RedisCacheManager.builder(connectionFactory)
            .cacheDefaults(config)
            .build();
    }
}

@Service
public class ProductService {
    
    // L2: Memory cache (fastest)
    @Cacheable(value = "products", cacheManager = "caffeineCacheManager", key = "#id")
    public Product getProduct(Long id) {
        // L3: Redis cache
        return getProductFromRedis(id)
            .orElseGet(() -> {
                // L4: Database
                Product product = productRepository.findById(id).orElseThrow();
                cacheInRedis(id, product);
                return product;
            });
    }
    
    private Optional<Product> getProductFromRedis(Long id) {
        // Redis lookup
        return Optional.ofNullable(redisTemplate.opsForValue().get("product:" + id));
    }
    
    private void cacheInRedis(Long id, Product product) {
        redisTemplate.opsForValue().set(
            "product:" + id,
            product,
            Duration.ofHours(1)
        );
    }
}
```

**AWS ElastiCache (Redis) Scaling**:
```yaml
Resources:
  ElastiCacheCluster:
    Type: AWS::ElastiCache::ReplicationGroup
    Properties:
      ReplicationGroupId: myapp-redis
      Description: Redis cluster for caching
      Engine: redis
      CacheNodeType: cache.r6g.large
      NumCacheClusters: 3  # Multi-AZ for HA
      AutomaticFailoverEnabled: true
      MultiAZEnabled: true
      SnapshotRetentionLimit: 7
      SnapshotWindow: "03:00-05:00"
```

**Kubernetes: Redis Deployment**:
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
spec:
  serviceName: redis
  replicas: 3
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        - name: redis-data
          mountPath: /data
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```

### 6.2 Cache-Aside Pattern

**Implementation**:
```java
@Service
public class CacheAsideService {
    
    private final ProductRepository productRepository;
    private final RedisTemplate<String, Product> redisTemplate;
    
    public Product getProduct(Long id) {
        // 1. Check cache
        String cacheKey = "product:" + id;
        Product cached = redisTemplate.opsForValue().get(cacheKey);
        if (cached != null) {
            return cached;
        }
        
        // 2. Cache miss - load from database
        Product product = productRepository.findById(id)
            .orElseThrow(() -> new ProductNotFoundException("Product not found: " + id));
        
        // 3. Store in cache
        redisTemplate.opsForValue().set(cacheKey, product, Duration.ofHours(1));
        
        return product;
    }
    
    public void updateProduct(Product product) {
        // 1. Update database
        productRepository.save(product);
        
        // 2. Invalidate cache
        String cacheKey = "product:" + product.getId();
        redisTemplate.delete(cacheKey);
        
        // Optional: Update cache with new value
        // redisTemplate.opsForValue().set(cacheKey, product, Duration.ofHours(1));
    }
}
```

### 6.3 Write-Through and Write-Behind Patterns

**Write-Through**:
```java
@Service
public class WriteThroughService {
    
    public void updateProduct(Product product) {
        // 1. Update cache
        String cacheKey = "product:" + product.getId();
        redisTemplate.opsForValue().set(cacheKey, product, Duration.ofHours(1));
        
        // 2. Update database (synchronous)
        productRepository.save(product);
    }
}
```

**Write-Behind (Async)**:
```java
@Service
public class WriteBehindService {
    
    private final ExecutorService executorService;
    
    public void updateProduct(Product product) {
        // 1. Update cache immediately
        String cacheKey = "product:" + product.getId();
        redisTemplate.opsForValue().set(cacheKey, product, Duration.ofHours(1));
        
        // 2. Update database asynchronously
        executorService.submit(() -> {
            try {
                productRepository.save(product);
            } catch (Exception e) {
                log.error("Failed to update database", e);
                // Retry logic or dead letter queue
            }
        });
    }
}
```

---

## 7. Database Scaling Patterns

### 7.1 Read Replicas

**AWS RDS Read Replicas**:
```yaml
Resources:
  RDSMaster:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: myapp-db-master
      Engine: postgres
      MasterUsername: admin
      MasterUserPassword: !Ref DatabasePassword
      DBInstanceClass: db.m5.large
      AllocatedStorage: 100
  
  RDSReadReplica:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: myapp-db-replica
      SourceDBInstanceIdentifier: !Ref RDSMaster
      DBInstanceClass: db.m5.large
      PubliclyAccessible: false
```

**Java Application: Read/Write Splitting**:
```java
@Configuration
public class DatabaseConfiguration {
    
    @Bean
    @Primary
    public DataSource masterDataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl("jdbc:postgresql://master-db:5432/myapp");
        config.setUsername("admin");
        config.setPassword("password");
        return new HikariDataSource(config);
    }
    
    @Bean
    public DataSource replicaDataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl("jdbc:postgresql://replica-db:5432/myapp");
        config.setUsername("admin");
        config.setPassword("password");
        return new HikariDataSource(config);
    }
    
    @Bean
    public AbstractRoutingDataSource routingDataSource() {
        ReplicationRoutingDataSource routingDataSource = new ReplicationRoutingDataSource();
        Map<Object, Object> dataSourceMap = new HashMap<>();
        dataSourceMap.put("master", masterDataSource());
        dataSourceMap.put("replica", replicaDataSource());
        routingDataSource.setTargetDataSources(dataSourceMap);
        routingDataSource.setDefaultTargetDataSource(masterDataSource());
        return routingDataSource;
    }
}

@Component
public class ReplicationRoutingDataSource extends AbstractRoutingDataSource {
    
    @Override
    protected Object determineCurrentLookupKey() {
        return TransactionSynchronizationManager.isCurrentTransactionReadOnly() 
            ? "replica" 
            : "master";
    }
}

@Service
@Transactional(readOnly = true)  // Routes to replica
public class ProductService {
    
    public Product getProduct(Long id) {
        // Read operation → replica
        return productRepository.findById(id).orElseThrow();
    }
    
    @Transactional  // Routes to master
    public Product createProduct(Product product) {
        // Write operation → master
        return productRepository.save(product);
    }
}
```

### 7.2 Database Sharding

**Sharding Strategy**:
```java
@Service
public class ShardedOrderService {
    
    private final Map<String, OrderRepository> shards;
    
    public ShardedOrderService(List<OrderRepository> repositories) {
        this.shards = repositories.stream()
            .collect(Collectors.toMap(
                repo -> repo.getShardId(),
                repo -> repo
            ));
    }
    
    private String getShardKey(Long orderId) {
        // Consistent hashing
        int shardCount = shards.size();
        int shardIndex = (int) (orderId % shardCount);
        return "shard-" + shardIndex;
    }
    
    public Order getOrder(Long orderId) {
        String shardKey = getShardKey(orderId);
        OrderRepository repository = shards.get(shardKey);
        return repository.findById(orderId).orElseThrow();
    }
    
    public Order createOrder(Order order) {
        String shardKey = getShardKey(order.getId());
        OrderRepository repository = shards.get(shardKey);
        return repository.save(order);
    }
}
```

**AWS RDS: Multi-AZ and Read Replicas**:
```yaml
# Master in us-east-1a
RDSMaster:
  AvailabilityZone: us-east-1a
  MultiAZ: true  # Standby in us-east-1b

# Read Replicas
RDSReplica1:
  AvailabilityZone: us-east-1b
  SourceDBInstanceIdentifier: !Ref RDSMaster

RDSReplica2:
  AvailabilityZone: us-east-1c
  SourceDBInstanceIdentifier: !Ref RDSMaster
```

### 7.3 Connection Pooling

**HikariCP Configuration for Scale**:
```yaml
# application.yml
spring:
  datasource:
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      leak-detection-threshold: 60000
      pool-name: MyAppHikariPool
```

**Java Configuration**:
```java
@Configuration
public class HikariConfiguration {
    
    @Bean
    public DataSource dataSource() {
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl("jdbc:postgresql://db:5432/myapp");
        config.setUsername("admin");
        config.setPassword("password");
        
        // Connection pool sizing
        config.setMaximumPoolSize(20);
        config.setMinimumIdle(5);
        
        // Timeouts
        config.setConnectionTimeout(30000);
        config.setIdleTimeout(600000);
        config.setMaxLifetime(1800000);
        
        // Performance
        config.setLeakDetectionThreshold(60000);
        config.setConnectionTestQuery("SELECT 1");
        
        return new HikariDataSource(config);
    }
}
```

---

## 8. Container Orchestration Scaling

### 8.1 Kubernetes Cluster Autoscaler

**Cluster Autoscaler Configuration**:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      containers:
      - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.24.0
        name: cluster-autoscaler
        command:
        - ./cluster-autoscaler
        - --v=4
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/myapp-cluster
        env:
        - name: AWS_REGION
          value: us-east-1
        resources:
          limits:
            cpu: 100m
            memory: 300Mi
          requests:
            cpu: 100m
            memory: 300Mi
```

**Node Group Configuration**:
```yaml
Resources:
  NodeGroup:
    Type: AWS::EKS::Nodegroup
    Properties:
      ClusterName: !Ref EKSCluster
      NodegroupName: myapp-nodegroup
      InstanceTypes:
        - t3.medium
      ScalingConfig:
        MinSize: 2
        MaxSize: 10
        DesiredSize: 3
      Labels:
        k8s.io/cluster-autoscaler/enabled: "true"
        k8s.io/cluster-autoscaler/myapp-cluster: "owned"
```

### 8.2 ECS Capacity Providers

**ECS Capacity Provider (Fargate Spot)**:
```yaml
Resources:
  FargateCapacityProvider:
    Type: AWS::ECS::CapacityProvider
    Properties:
      Name: FARGATE_SPOT
      AutoScalingGroupProvider:
        AutoScalingGroupArn: !Ref AutoScalingGroup
        ManagedScaling:
          Status: ENABLED
          TargetCapacity: 100
          MinimumScalingStepSize: 1
          MaximumScalingStepSize: 10000
        ManagedTerminationProtection: ENABLED
  
  Cluster:
    Type: AWS::ECS::Cluster
    Properties:
      ClusterName: myapp-cluster
      CapacityProviders:
        - FARGATE
        - FARGATE_SPOT
      DefaultCapacityProviderStrategy:
        - CapacityProvider: FARGATE_SPOT
          Weight: 4
        - CapacityProvider: FARGATE
          Weight: 1
```

### 8.3 Pod Disruption Budget

**Kubernetes: Pod Disruption Budget**:
```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: myapp-pdb
spec:
  minAvailable: 2  # Always keep at least 2 pods running
  selector:
    matchLabels:
      app: myapp
```

**Alternative (maxUnavailable)**:
```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: myapp-pdb
spec:
  maxUnavailable: 1  # Allow 1 pod to be unavailable
  selector:
    matchLabels:
      app: myapp
```

---

## 9. Real-World Implementation

### 9.1 Complete Scalable Architecture

**Architecture Diagram**:
```
┌─────────────────────────────────────────────────────────────┐
│                    CloudFront (CDN)                         │
│                  Global Edge Locations                      │
└──────────────────────┬──────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│              Application Load Balancer (ALB)                 │
│              Multi-AZ, Health Checks                        │
└──────────────────────┬──────────────────────────────────────┘
                       │
        ┌──────────────┼──────────────┐
        ▼              ▼              ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│ ECS Service  │ │ ECS Service  │ │ ECS Service  │
│  (AZ-1)      │ │  (AZ-2)      │ │  (AZ-3)      │
│  5 tasks     │ │  5 tasks     │ │  5 tasks     │
└──────┬───────┘ └──────┬───────┘ └──────┬───────┘
       │                │                 │
       └────────────────┼─────────────────┘
                        │
        ┌───────────────┼───────────────┐
        ▼               ▼               ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│ RDS Master   │ │ RDS Replica  │ │ RDS Replica  │
│  (AZ-1)      │ │  (AZ-2)      │ │  (AZ-3)      │
└──────────────┘ └──────────────┘ └──────────────┘
        │               │                 │
        └───────────────┼─────────────────┘
                        │
        ┌───────────────┼───────────────┐
        ▼               ▼               ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│ ElastiCache │ │ ElastiCache   │ │ ElastiCache  │
│  (Redis)    │ │  (Redis)      │ │  (Redis)     │
│  Primary    │ │  Replica      │ │  Replica     │
└──────────────┘ └──────────────┘ └──────────────┘
```

### 9.2 Docker Compose: Multi-Container Scaling

**docker-compose.yml**:
```yaml
version: '3.8'
services:
  app:
    image: myapp:latest
    deploy:
      replicas: 5
      update_config:
        parallelism: 2
        delay: 10s
      restart_policy:
        condition: on-failure
    environment:
      - DB_HOST=db
      - REDIS_HOST=redis
    depends_on:
      - db
      - redis
    networks:
      - app-network
  
  db:
    image: postgres:14
    environment:
      - POSTGRES_DB=myapp
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=password
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - app-network
  
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - app-network
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - app
    networks:
      - app-network

volumes:
  db-data:
  redis-data:

networks:
  app-network:
    driver: bridge
```

**nginx.conf (Load Balancer)**:
```nginx
upstream app {
    least_conn;
    server app:8080;
    server app:8080;
    server app:8080;
    server app:8080;
    server app:8080;
}

server {
    listen 80;
    
    location / {
        proxy_pass http://app;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
    
    location /health {
        access_log off;
        proxy_pass http://app/actuator/health;
    }
}
```

### 9.3 Kubernetes: Complete Scaling Setup

**Deployment with HPA and VPA**:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myapp:latest
        ports:
        - containerPort: 8080
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
---
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: myapp-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  updatePolicy:
    updateMode: "Auto"
```

---

## 10. Best Practices and Patterns

### 10.1 Scalability Best Practices

**Application Design**:
1. **Stateless Applications**: No session state in application
2. **Horizontal Scaling First**: Prefer scale-out over scale-up
3. **Async Processing**: Use queues for long-running tasks
4. **Caching Strategy**: Multi-layer caching
5. **Database Optimization**: Indexes, connection pooling, read replicas

**Infrastructure**:
1. **Multi-AZ Deployment**: High availability
2. **Auto-Scaling**: Based on metrics
3. **Load Balancing**: Distribute traffic
4. **Health Checks**: Automatic failure detection
5. **Monitoring**: Track metrics and alerts

**Cost Optimization**:
1. **Right-Sizing**: Match resources to needs
2. **Spot Instances**: For non-critical workloads
3. **Reserved Instances**: For steady workloads
4. **Lifecycle Policies**: Automate resource cleanup

### 10.2 Anti-Patterns to Avoid

**❌ Stateful Applications**:
```java
// BAD: Session state in memory
private Map<String, Session> sessions = new HashMap<>();

// GOOD: External session storage
@Autowired
private RedisTemplate<String, Session> redisTemplate;
```

**❌ Vertical Scaling Only**:
```yaml
# BAD: Only scale up
resources:
  limits:
    cpu: "8"
    memory: "16Gi"

# GOOD: Scale horizontally
replicas: 10
resources:
  limits:
    cpu: "1"
    memory: "2Gi"
```

**❌ No Health Checks**:
```yaml
# BAD: No health checks
containers:
- name: myapp
  image: myapp:latest

# GOOD: Health checks configured
containers:
- name: myapp
  image: myapp:latest
  livenessProbe:
    httpGet:
      path: /actuator/health
      port: 8080
  readinessProbe:
    httpGet:
      path: /actuator/health
      port: 8080
```

### 10.3 Monitoring and Observability

**Key Metrics to Monitor**:
```yaml
Application Metrics:
  - Request rate (RPS)
  - Response time (p50, p95, p99)
  - Error rate
  - Active connections

Infrastructure Metrics:
  - CPU utilization
  - Memory utilization
  - Network I/O
  - Disk I/O

Database Metrics:
  - Connection pool usage
  - Query performance
  - Replication lag
  - Cache hit rate

Auto-Scaling Metrics:
  - Current replicas
  - Desired replicas
  - Scaling events
  - Scale-up/down frequency
```

**Java Application: Metrics Export**:
```java
@Configuration
public class MetricsConfiguration {
    
    @Bean
    public MeterRegistryCustomizer<MeterRegistry> metricsCustomizer() {
        return registry -> {
            registry.config().commonTags(
                "application", "myapp",
                "environment", "production"
            );
        };
    }
    
    @Bean
    public TimedAspect timedAspect(MeterRegistry registry) {
        return new TimedAspect(registry);
    }
}

@Service
public class OrderService {
    
    @Timed(value = "orders.processing", description = "Order processing time")
    public Order processOrder(OrderRequest request) {
        // Process order
        return order;
    }
}
```

---

## Summary

### Key Scalability Patterns

1. **Horizontal Scaling**: Add more instances (preferred)
2. **Vertical Scaling**: Increase resources (limited)
3. **Auto-Scaling**: Automatic based on metrics
4. **Load Balancing**: Distribute traffic
5. **Caching**: Multi-layer caching strategy
6. **Database Scaling**: Read replicas, sharding
7. **Container Orchestration**: Kubernetes/ECS scaling
8. **Stateless Design**: Enable horizontal scaling

### Implementation Stack

**AWS Services**:
- ECS/EKS for container orchestration
- ALB for load balancing
- Auto Scaling for automatic scaling
- ElastiCache for caching
- RDS with read replicas
- CloudWatch for monitoring

**Docker**:
- Containerization
- Multi-stage builds
- Health checks
- Resource limits

**Kubernetes**:
- HPA for pod scaling
- VPA for resource optimization
- Cluster Autoscaler for node scaling
- Service and Ingress for load balancing

**Java/Spring Boot**:
- Stateless application design
- Connection pooling
- Caching (Caffeine, Redis)
- Metrics and monitoring
- Health checks

---

**This comprehensive guide covers all aspects of scalability patterns using AWS, Docker, and Kubernetes, with practical implementations for Java applications.**

