# 50 Hours of Mid-Level System Design in One Hour - Comprehensive Guide

## Table of Contents
1. [System Design Fundamentals](#system-design-fundamentals)
2. [Core Design Principles](#core-design-principles)
3. [Scalability Patterns](#scalability-patterns)
4. [Database Design](#database-design)
5. [Caching Strategies](#caching-strategies)
6. [Load Balancing](#load-balancing)
7. [Message Queues & Event-Driven Architecture](#message-queues--event-driven-architecture)
8. [Microservices Architecture](#microservices-architecture)
9. [API Design](#api-design)
10. [Security & Authentication](#security--authentication)
11. [Monitoring & Observability](#monitoring--observability)
12. [Common System Design Patterns](#common-system-design-patterns)
13. [Real-World System Examples](#real-world-system-examples)
14. [Interview Framework](#interview-framework)
15. [Quick Reference](#quick-reference)

---

## System Design Fundamentals

### What is System Design?

**System Design** is:
- **Architecture Planning**: Designing the architecture of a system
- **Scalability**: Ensuring system can handle growth
- **Reliability**: Ensuring system is reliable and available
- **Performance**: Optimizing for performance
- **Trade-offs**: Making informed trade-offs

### Key Concepts

**1. Scalability**
- **Vertical Scaling**: Scale up (bigger machines)
- **Horizontal Scaling**: Scale out (more machines)
- **Stateless Services**: Services without state
- **Load Distribution**: Distribute load across servers

**2. Reliability**
- **Availability**: System uptime percentage
- **Fault Tolerance**: Handle failures gracefully
- **Redundancy**: Duplicate components
- **Failover**: Automatic switching to backup

**3. Performance**
- **Latency**: Time to respond
- **Throughput**: Requests per second
- **Efficiency**: Resource utilization
- **Optimization**: Reduce bottlenecks

**4. Consistency**
- **Strong Consistency**: All nodes see same data
- **Eventual Consistency**: Eventually consistent
- **CAP Theorem**: Consistency, Availability, Partition tolerance
- **ACID**: Atomicity, Consistency, Isolation, Durability

---

## Core Design Principles

### 1. Separation of Concerns

**Principle:**
- **Modularity**: Break system into modules
- **Single Responsibility**: Each component has one job
- **Loose Coupling**: Components interact loosely
- **High Cohesion**: Related functionality together

**Example:**
```
User Service (User management)
Order Service (Order processing)
Payment Service (Payment processing)
Notification Service (Notifications)
```

### 2. Scalability First

**Approach:**
- **Design for Scale**: Plan for growth from start
- **Horizontal Scaling**: Prefer horizontal over vertical
- **Stateless Design**: Make services stateless
- **Database Sharding**: Partition data

**Example:**
```
Stateless API servers → Load Balancer → Multiple instances
Database → Sharded by user_id → Multiple database instances
```

### 3. Fault Tolerance

**Strategy:**
- **Redundancy**: Multiple instances
- **Circuit Breaker**: Prevent cascading failures
- **Retry Logic**: Retry failed operations
- **Graceful Degradation**: Degrade gracefully

**Example:**
```
Primary Service → Fails → Circuit Breaker Opens → Fallback Service
```

### 4. Performance Optimization

**Techniques:**
- **Caching**: Cache frequently accessed data
- **CDN**: Content Delivery Network
- **Database Indexing**: Index frequently queried fields
- **Async Processing**: Process asynchronously

**Example:**
```
Request → Cache (Redis) → If miss → Database → Store in cache
```

---

## Scalability Patterns

### 1. Horizontal Scaling

**Pattern:**
```
Single Server → Multiple Servers → Load Balancer
```

**Benefits:**
- **Unlimited Scale**: Add more servers
- **Cost Effective**: Use commodity hardware
- **Fault Tolerance**: One server fails, others continue

**Implementation:**
```java
// Stateless service
@RestController
public class UserController {
    @GetMapping("/users/{id}")
    public User getUser(@PathVariable String id) {
        // No local state, can run on any server
        return userService.findById(id);
    }
}
```

### 2. Vertical Scaling

**Pattern:**
```
Small Server → Medium Server → Large Server
```

**When to Use:**
- **Single Machine**: Can't distribute
- **Stateful**: Requires shared state
- **Quick Fix**: Temporary solution

**Limitations:**
- **Hardware Limits**: Limited by hardware
- **Cost**: Expensive at scale
- **Single Point of Failure**: One machine

### 3. Database Scaling

**Patterns:**

**Read Replicas:**
```
Master DB (Write) → Replicas (Read)
```

**Sharding:**
```
Database → Shard 1 (users 0-1000)
         → Shard 2 (users 1001-2000)
         → Shard 3 (users 2001-3000)
```

**Partitioning:**
```
Table → Partition by date
     → Partition by region
     → Partition by user_id
```

### 4. Caching Layers

**Multi-Level Caching:**
```
L1: Application Cache (In-Memory)
L2: Distributed Cache (Redis)
L3: CDN Cache
L4: Database Cache
```

---

## Database Design

### 1. Database Types

**SQL Databases:**
- **ACID**: Strong consistency
- **Relations**: Relational data
- **Transactions**: ACID transactions
- **Examples**: PostgreSQL, MySQL, Oracle

**NoSQL Databases:**
- **Document**: MongoDB, CouchDB
- **Key-Value**: Redis, DynamoDB
- **Column**: Cassandra, HBase
- **Graph**: Neo4j

### 2. Database Patterns

**Master-Slave Replication:**
```
Master (Write) → Replicas (Read)
```

**Master-Master Replication:**
```
Master 1 ↔ Master 2 (Both read/write)
```

**Sharding:**
```
Shard 1 (users 0-1M)
Shard 2 (users 1M-2M)
Shard 3 (users 2M-3M)
```

### 3. Database Optimization

**Indexing:**
```sql
-- Index frequently queried columns
CREATE INDEX idx_user_email ON users(email);
CREATE INDEX idx_order_user_id ON orders(user_id);
```

**Query Optimization:**
```sql
-- Use EXPLAIN to analyze queries
EXPLAIN SELECT * FROM users WHERE email = 'user@example.com';

-- Avoid N+1 queries
-- Bad: Multiple queries
SELECT * FROM users;
SELECT * FROM orders WHERE user_id = 1;
SELECT * FROM orders WHERE user_id = 2;

-- Good: Single query with JOIN
SELECT u.*, o.* FROM users u
LEFT JOIN orders o ON u.id = o.user_id;
```

**Connection Pooling:**
```java
// Reuse database connections
@Configuration
public class DatabaseConfig {
    @Bean
    public DataSource dataSource() {
        HikariConfig config = new HikariConfig();
        config.setMaximumPoolSize(20);
        config.setMinimumIdle(5);
        return new HikariDataSource(config);
    }
}
```

---

## Caching Strategies

### 1. Cache-Aside Pattern

**Pattern:**
```
1. Check cache
2. If miss, read from database
3. Store in cache
4. Return data
```

**Implementation:**
```java
public User getUser(String userId) {
    // Check cache
    User user = cache.get("user:" + userId);
    if (user != null) {
        return user;
    }
    
    // Cache miss - read from database
    user = database.getUser(userId);
    
    // Store in cache
    cache.set("user:" + userId, user, 3600); // TTL: 1 hour
    
    return user;
}
```

### 2. Write-Through Pattern

**Pattern:**
```
1. Write to cache
2. Write to database
3. Return success
```

**Implementation:**
```java
public void updateUser(User user) {
    // Write to cache
    cache.set("user:" + user.getId(), user);
    
    // Write to database
    database.updateUser(user);
}
```

### 3. Write-Behind Pattern

**Pattern:**
```
1. Write to cache
2. Return success
3. Async write to database
```

**Implementation:**
```java
public void updateUser(User user) {
    // Write to cache immediately
    cache.set("user:" + user.getId(), user);
    
    // Async write to database
    asyncQueue.enqueue(() -> database.updateUser(user));
}
```

### 4. Cache Invalidation

**Strategies:**
- **TTL**: Time-to-live expiration
- **LRU**: Least Recently Used eviction
- **Invalidation**: Manual invalidation
- **Versioning**: Cache versioning

**Implementation:**
```java
// TTL-based expiration
cache.set("user:123", user, 3600); // Expires in 1 hour

// Manual invalidation
public void updateUser(User user) {
    database.updateUser(user);
    cache.delete("user:" + user.getId()); // Invalidate cache
}
```

---

## Load Balancing

### 1. Load Balancing Algorithms

**Round Robin:**
```
Request 1 → Server 1
Request 2 → Server 2
Request 3 → Server 3
Request 4 → Server 1 (cycle)
```

**Least Connections:**
```
Request → Server with fewest active connections
```

**Weighted Round Robin:**
```
Server 1 (weight: 3) → 3 requests
Server 2 (weight: 1) → 1 request
```

**IP Hash:**
```
Hash(client IP) → Consistent server assignment
```

### 2. Load Balancer Types

**Layer 4 (Transport Layer):**
- **TCP/UDP**: Based on IP and port
- **Fast**: Lower overhead
- **Examples**: HAProxy, AWS Network Load Balancer

**Layer 7 (Application Layer):**
- **HTTP/HTTPS**: Based on content
- **Flexible**: Can route based on URL, headers
- **Examples**: NGINX, AWS Application Load Balancer

### 3. Load Balancer Placement

**Architecture:**
```
Internet → Load Balancer → Multiple App Servers
                ↓
         Database Cluster
```

**High Availability:**
```
Internet → Primary LB → App Servers
         → Secondary LB (Standby)
```

---

## Message Queues & Event-Driven Architecture

### 1. Message Queue Patterns

**Producer-Consumer:**
```
Producer → Queue → Consumer
```

**Pub-Sub:**
```
Publisher → Topic → Subscriber 1
                  → Subscriber 2
                  → Subscriber 3
```

**Request-Reply:**
```
Request → Queue → Worker → Reply Queue → Response
```

### 2. Message Queue Benefits

**Decoupling:**
- **Loose Coupling**: Services don't directly depend on each other
- **Async Processing**: Process asynchronously
- **Scalability**: Scale producers and consumers independently

**Reliability:**
- **Durability**: Messages persisted
- **Retry**: Automatic retry on failure
- **Dead Letter Queue**: Handle failed messages

### 3. Popular Message Queues

**RabbitMQ:**
- **Protocol**: AMQP
- **Features**: Routing, exchanges, queues
- **Use Case**: Complex routing needs

**Apache Kafka:**
- **Protocol**: Custom
- **Features**: High throughput, log-based
- **Use Case**: Event streaming, high volume

**Amazon SQS:**
- **Protocol**: HTTP/HTTPS
- **Features**: Managed, scalable
- **Use Case**: AWS-based systems

**Redis Pub/Sub:**
- **Protocol**: Redis protocol
- **Features**: Fast, simple
- **Use Case**: Real-time notifications

### 4. Event-Driven Architecture

**Pattern:**
```
Service A → Event → Event Bus → Service B
                              → Service C
                              → Service D
```

**Benefits:**
- **Loose Coupling**: Services communicate via events
- **Scalability**: Easy to add new consumers
- **Resilience**: Services can fail independently

**Example:**
```java
// Event Publisher
@Autowired
private EventPublisher eventPublisher;

public void createOrder(Order order) {
    orderRepository.save(order);
    
    // Publish event
    eventPublisher.publish(new OrderCreatedEvent(order));
}

// Event Subscriber
@EventListener
public void handleOrderCreated(OrderCreatedEvent event) {
    // Send notification
    notificationService.sendEmail(event.getOrder().getCustomerId());
    
    // Update inventory
    inventoryService.reserveItems(event.getOrder().getItems());
}
```

---

## Microservices Architecture

### 1. Microservices Principles

**Service Independence:**
- **Independent Deployment**: Deploy services independently
- **Technology Diversity**: Different tech stacks
- **Team Autonomy**: Teams own services
- **Fault Isolation**: Failures isolated

**Service Communication:**
- **REST APIs**: HTTP/REST
- **gRPC**: High-performance RPC
- **Message Queues**: Async communication
- **GraphQL**: Flexible queries

### 2. Microservices Patterns

**API Gateway:**
```
Client → API Gateway → Service 1
                    → Service 2
                    → Service 3
```

**Service Discovery:**
```
Service → Register → Service Registry
Client → Query Registry → Get Service Address
```

**Circuit Breaker:**
```
Service A → Circuit Breaker → Service B
         → If fails → Open circuit → Fallback
```

**Saga Pattern:**
```
Transaction → Step 1 (Service A)
           → Step 2 (Service B)
           → Step 3 (Service C)
           → If fails → Compensate
```

### 3. Microservices Challenges

**Distributed System Problems:**
- **Network Latency**: Network calls add latency
- **Partial Failures**: Services can fail independently
- **Data Consistency**: Harder to maintain consistency
- **Debugging**: Harder to debug across services

**Solutions:**
- **Service Mesh**: Handle cross-cutting concerns
- **Distributed Tracing**: Track requests across services
- **Event Sourcing**: Event-driven architecture
- **CQRS**: Separate read/write models

---

## API Design

### 1. REST API Principles

**RESTful Design:**
```
GET    /users          → List users
GET    /users/{id}     → Get user
POST   /users          → Create user
PUT    /users/{id}     → Update user
DELETE /users/{id}     → Delete user
```

**Resource Naming:**
```
Good:
/users
/users/{id}/orders
/orders/{id}/items

Bad:
/getUsers
/createUser
/userOrders
```

### 2. API Versioning

**URL Versioning:**
```
/v1/users
/v2/users
```

**Header Versioning:**
```
Accept: application/vnd.api.v1+json
```

**Query Parameter:**
```
/users?version=1
```

### 3. API Best Practices

**Pagination:**
```
GET /users?page=1&size=20
```

**Filtering:**
```
GET /users?status=active&role=admin
```

**Sorting:**
```
GET /users?sort=name,asc
```

**Error Handling:**
```json
{
  "error": {
    "code": "USER_NOT_FOUND",
    "message": "User with ID 123 not found",
    "timestamp": "2024-01-01T00:00:00Z"
  }
}
```

---

## Security & Authentication

### 1. Authentication Methods

**JWT (JSON Web Tokens):**
```
User → Login → Server → JWT Token
User → Request with JWT → Server validates → Response
```

**OAuth 2.0:**
```
User → Authorize → Authorization Server → Access Token
User → Request with Token → Resource Server → Response
```

**API Keys:**
```
Client → Request with API Key → Server validates → Response
```

### 2. Security Best Practices

**HTTPS:**
- **Encryption**: Encrypt data in transit
- **TLS/SSL**: Use TLS 1.2 or higher
- **Certificate**: Valid SSL certificates

**Input Validation:**
- **Sanitize**: Sanitize user input
- **Validate**: Validate data format
- **SQL Injection**: Use parameterized queries

**Rate Limiting:**
```
100 requests per minute per IP
1000 requests per hour per user
```

**CORS:**
```
Allow specific origins
Allow specific methods
Allow specific headers
```

---

## Monitoring & Observability

### 1. Three Pillars of Observability

**Metrics:**
- **Counters**: Request count, error count
- **Gauges**: CPU usage, memory usage
- **Histograms**: Response time distribution

**Logs:**
- **Structured Logging**: JSON format
- **Log Levels**: DEBUG, INFO, WARN, ERROR
- **Centralized Logging**: Aggregate logs

**Traces:**
- **Distributed Tracing**: Track requests across services
- **Span**: Single operation
- **Trace**: Complete request flow

### 2. Monitoring Tools

**Metrics:**
- **Prometheus**: Time-series database
- **Grafana**: Visualization
- **CloudWatch**: AWS monitoring

**Logging:**
- **ELK Stack**: Elasticsearch, Logstash, Kibana
- **Splunk**: Enterprise logging
- **CloudWatch Logs**: AWS logging

**Tracing:**
- **Jaeger**: Distributed tracing
- **Zipkin**: Distributed tracing
- **AWS X-Ray**: AWS tracing

### 3. Alerting

**Alert Rules:**
```
Error rate > 5% → Alert
Response time > 1s → Alert
CPU usage > 80% → Alert
Memory usage > 90% → Alert
```

---

## Common System Design Patterns

### 1. Rate Limiting

**Token Bucket:**
```
Bucket with tokens
Request consumes token
Tokens refill at rate
```

**Sliding Window:**
```
Track requests in time window
Reject if exceeds limit
```

**Fixed Window:**
```
Count requests in fixed window
Reset at window end
```

### 2. Idempotency

**Idempotent Operations:**
```
Same request → Same result
Use idempotency keys
Store request IDs
```

**Implementation:**
```java
public void processPayment(String idempotencyKey, Payment payment) {
    // Check if already processed
    if (processedRequests.contains(idempotencyKey)) {
        return; // Already processed
    }
    
    // Process payment
    processPayment(payment);
    
    // Mark as processed
    processedRequests.add(idempotencyKey);
}
```

### 3. Circuit Breaker

**States:**
```
Closed → Normal operation
Open → Failing, reject requests
Half-Open → Testing if recovered
```

**Implementation:**
```java
@CircuitBreaker(name = "payment-service", fallbackMethod = "fallback")
public PaymentResult processPayment(Payment payment) {
    return paymentService.process(payment);
}

public PaymentResult fallback(Payment payment, Exception e) {
    // Fallback logic
    return PaymentResult.pending();
}
```

### 4. Bulkhead Pattern

**Isolation:**
```
Separate resources for different operations
Prevent cascading failures
```

**Example:**
```
Thread Pool 1 → Critical operations
Thread Pool 2 → Non-critical operations
```

---

## Real-World System Examples

### 1. URL Shortener (TinyURL)

**Requirements:**
- Shorten long URLs
- Redirect to original URL
- 100M URLs per day
- 100:1 read/write ratio

**Design:**
```
Client → Load Balancer → App Servers
                      → Cache (Redis)
                      → Database (Sharded)
```

**Key Components:**
- **Base62 Encoding**: Short URL generation
- **Hash Function**: MD5/SHA for URL hashing
- **Cache**: Redis for hot URLs
- **Database**: Sharded by hash

### 2. Twitter/Feed System

**Requirements:**
- Post tweets
- Follow users
- Timeline feed
- 500M users, 200M tweets/day

**Design:**
```
Write Path:
User → Post Tweet → Write Service → Database
                                    → Fan-out to followers

Read Path:
User → Timeline → Read Service → Cache → Database
```

**Key Components:**
- **Fan-out**: Push to followers' timelines
- **Timeline Cache**: Pre-computed timelines
- **Database Sharding**: Shard by user_id

### 3. Chat/Messaging System

**Requirements:**
- Send messages
- Real-time delivery
- 1B users, 50B messages/day

**Design:**
```
Client → Load Balancer → Message Service
                      → WebSocket Server
                      → Message Queue (Kafka)
                      → Database
```

**Key Components:**
- **WebSocket**: Real-time communication
- **Message Queue**: Kafka for message delivery
- **Presence Service**: Track online users
- **Database**: Store messages

### 4. Video Streaming (YouTube)

**Requirements:**
- Upload videos
- Stream videos
- 1B users, 1B hours watched/day

**Design:**
```
Upload:
Client → Upload Service → Storage (S3)
                       → Transcoding Service
                       → CDN

Stream:
Client → CDN → Video Files
```

**Key Components:**
- **CDN**: Content delivery network
- **Transcoding**: Multiple quality levels
- **Storage**: Object storage (S3)
- **Caching**: CDN caching

---

## Interview Framework

### 1. Requirements Clarification

**Ask:**
- **Scale**: Users, requests per second
- **Features**: Core features, nice-to-have
- **Constraints**: Latency, consistency requirements
- **Assumptions**: Clarify assumptions

### 2. High-Level Design

**Steps:**
1. **Draw Components**: Main components
2. **Show Flow**: Request flow
3. **Identify APIs**: Key APIs
4. **Database Schema**: Data model

### 3. Detailed Design

**Deep Dive:**
- **Scaling**: How to scale each component
- **Caching**: Caching strategy
- **Database**: Database design, sharding
- **Load Balancing**: Load balancing strategy

### 4. Trade-offs

**Discuss:**
- **Consistency vs Availability**: CAP theorem
- **Latency vs Throughput**: Performance trade-offs
- **Cost vs Performance**: Cost considerations
- **Complexity vs Simplicity**: Complexity trade-offs

### 5. Optimization

**Optimize:**
- **Bottlenecks**: Identify bottlenecks
- **Caching**: Add caching layers
- **Database**: Optimize queries
- **CDN**: Use CDN for static content

---

## Quick Reference

### Scalability Checklist

- [ ] Horizontal scaling possible
- [ ] Stateless services
- [ ] Database sharding/replication
- [ ] Caching strategy
- [ ] CDN for static content
- [ ] Load balancing
- [ ] Message queues for async processing

### Performance Checklist

- [ ] Database indexing
- [ ] Query optimization
- [ ] Caching frequently accessed data
- [ ] CDN for static assets
- [ ] Connection pooling
- [ ] Async processing where possible

### Reliability Checklist

- [ ] Redundancy (multiple instances)
- [ ] Failover mechanisms
- [ ] Circuit breakers
- [ ] Retry logic
- [ ] Health checks
- [ ] Monitoring and alerting

### Security Checklist

- [ ] HTTPS/TLS
- [ ] Authentication/Authorization
- [ ] Input validation
- [ ] Rate limiting
- [ ] SQL injection prevention
- [ ] XSS prevention
- [ ] CORS configuration

---

## Summary

### Key Takeaways

1. **Start Simple**: Begin with simple design, scale as needed
2. **Think Scale**: Design for scalability from the start
3. **Use Caching**: Cache frequently accessed data
4. **Database Design**: Proper indexing, sharding, replication
5. **Load Balancing**: Distribute load across servers
6. **Message Queues**: Use for async processing
7. **Monitoring**: Monitor everything
8. **Trade-offs**: Understand and communicate trade-offs

### Common Patterns

- **Cache-Aside**: Check cache, then database
- **Write-Through**: Write to cache and database
- **Read Replicas**: Master for writes, replicas for reads
- **Sharding**: Partition data across databases
- **Circuit Breaker**: Prevent cascading failures
- **Rate Limiting**: Control request rate

### Interview Tips

1. **Clarify Requirements**: Ask questions
2. **Think Out Loud**: Explain your thinking
3. **Start High-Level**: Begin with high-level design
4. **Deep Dive**: Go into details when asked
5. **Discuss Trade-offs**: Mention trade-offs
6. **Optimize**: Suggest optimizations

---

**Guide Complete** - This comprehensive guide covers 50 hours of mid-level system design concepts condensed into key patterns, principles, and practices!

